### Mini Description

Seeks to understand the nature of ethical statements, attitudes, motivation, properties, and judgements.

### Description

Metaethics can be viewed as the endeavor to know what normative framework to use and when. It is thus something to be practiced by both AI designers and potentially even AIs. It is a topic rarely covered by ethicists and AI engineers in the context of value alignment and there is thus little to no research about it. In the short term, it might be the case that its relevance is low as the ethical impacts of metaethical disagreements for normative theory and applied ethics are limited in the world. In the long term, however, if superintelligence is created and the cosmic endowment can be optimized to some end then metaethics becomes crucially important. We can understand the importance of metaethics here as metaphysical and epistemological issues regarding what beneficial intelligence entails. To what end should we aim intelligence and why? This can be captured as debates between moral realist and moral anti-realist positions, which consequently have said metaphysical and epistemological implications in ethics and thus in what it means to be a beneficial AI. One cannot continue with the project of generating beneficial AI without a clear understanding of beneficial. This question largely exists in the domain of metaethics.

This may be the most difficult form of ethics to develop in machines as it is the most abstract, but more technical research is needed on abstract concept representations in AI. If metaethics is instantiated or developed in AI then AI will not only be ethical decision makers, but also ethical reasoners as well. This would be a necessary but not sufficient condition for creating beneficial AGIs and thus represents one of the most crucial parts to long-term value alignment. Answering the question of what is good and valuable in the world and why? is an interdependently necessary part of value alignment and may be one of few things left to contemplate once intelligence is solved.

Here are some important questions to consider here: What are the impacts of specific metaethical theories? How much would some position change our current paths on value alignment? How would it change technical AI research? What probabilities am I assigning to different metaethical theories? How does the interplay of uncertainty and potential impact of specific positions affect how we ought to proceed with value alignment?

### Related Nodes

- [Normative Ethics](/Value_Alignment/Ethics/Normative_Ethics/Normative_Ethics.md)
