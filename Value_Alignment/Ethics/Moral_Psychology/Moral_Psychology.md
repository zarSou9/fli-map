### Mini Description

Seeks to understand morality as a human phenomenon at the level of the mind and/or brain. It looks to answer questions about moral development, motivation, reasoning, and character.

### Description

Moral psychology intersects with AI at a multitude of contact points in relation to human design of AI as well as human interaction with and reception of AI systems. Regarding the former, understanding moral psychology is helpful for elucidating and rooting out bias in the designers of AI systems, making sure such bias doesnt make it onto systems intentionally or unintentionally, is helpful for promoting cooperation and resolving game theoretic situations between parties competing to create advanced AI systems, and more. Regarding the latter, understanding moral psychology provides a framework for understanding the conceptual structure(s) which guides and constrains human social behavior. It thus functions to specify and/or predict how humans will interact with certain kinds of AI systems and what features said AI systems must contain in order to properly function in relation to human moral psychology. If moral psychology is ignored, we risk generating AIs which feel unethical or adversarial as they violate or come into conflict our moral psychology even if it is the case that they are morally superior or far more benevolent than ourselves. In terms of preference aggregation, moral psychology may also help identify general trends and preferences that are more or less hard-wired across humanity. This may  assist in narrowing the space of general human preferences and moral attitudes. It can also provide insight into ethics in general by identifying where our actual preferences are not aligned with our posited ethical philosophy or what we think we ought to prefer or value. In the long-term, powerful AI systems may develop robust models of human moral psychology which can be used to manipulate or help to make us more moral. The uses of moral psychology in AI safety are plentiful and are certainly not fully captured here.
